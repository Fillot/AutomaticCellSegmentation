{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tom's pipeline for automated FISH analysis\n",
    "\n",
    "v0.1 : semi-automated notebook for automated segmentation of microscopy images\n",
    "\n",
    "We start by importing all the files and libraries used to run this pipeline.\n",
    "\n",
    "Requirement: \n",
    "    standard:\n",
    "        - numpy\n",
    "        - os\n",
    "        - pathlib\n",
    "        - glob\n",
    "        - PIL\n",
    "        - skimage\n",
    "    non-standard:\n",
    "        - cellpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom libraries. \n",
    "# The corresponding files (for ex., autosegmentation.py) \n",
    "# must be in the same folder as this notebook\n",
    "import autosegmentation as seg\n",
    "import sanitize\n",
    "import readwrite as rw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start the processing, enter the path to the folder that contains the images, for the variable root_folder. \"exemple_data\" is a folder in this folder, containing some microscopy images of p21 FISH & p53 IF combined. If the data isn't in the same directory as the notebook, you have to provide the full path to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = \"/home/tom/Documents/Scientifique/Thesis/Data/27X/271\"\n",
    "rw.prepare_folders(root_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we read all the .tif in the folder, save the splitted channels separately (for FISHQuant) and do the max projections (for Cellpose)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing nutlin_15_MMStack_Pos0.ome.tif\n",
      "Processing nutlin_13_MMStack_Pos0.ome.tif\n",
      "Processing nutlin_18_MMStack_Pos0.ome.tif\n",
      "Processing nutlin_12_MMStack_Pos0.ome.tif\n",
      "Processing DMSO_11_MMStack_Pos0.ome.tif\n",
      "Processing DMSO_3_MMStack_Pos0.ome.tif\n",
      "Processing DMSO_3_MMStack_Pos0.ome.tif\n",
      "Processing nutlin_1_MMStack_Pos0.ome.tif\n"
     ]
    }
   ],
   "source": [
    "rw.split_and_project(root_folder, all_tiff = True, red=3, green=1, blue=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use cellpose to generate the outlines on all the max projections. By default the GPU is turned on, which I find not only works much faster, but also leads to less crashes, which is important because Cellpose can crashes without throwing you an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging file doesn't exist\n",
      "exemple_data/max_projections/DMSO_1_MAX.tif\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:3826: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  \"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time spent: running network 0.53s; flow+mask computation 13.37\n",
      "estimated masks for 1 image(s) in 13.98 sec\n",
      ">>>> TOTAL TIME 13.98 sec\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "time spent: running network 0.45s; flow+mask computation 2.47\n",
      "estimated masks for 1 image(s) in 2.97 sec\n",
      ">>>> TOTAL TIME 2.97 sec\n",
      "exemple_data/max_projections/DMSO_2_MAX.tif\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "time spent: running network 0.48s; flow+mask computation 3.44\n",
      "estimated masks for 1 image(s) in 3.97 sec\n",
      ">>>> TOTAL TIME 3.97 sec\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "time spent: running network 0.33s; flow+mask computation 1.73\n",
      "estimated masks for 1 image(s) in 2.10 sec\n",
      ">>>> TOTAL TIME 2.10 sec\n",
      "exemple_data/max_projections/DMSO_3_MAX.tif\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "time spent: running network 0.28s; flow+mask computation 8.85\n",
      "estimated masks for 1 image(s) in 9.20 sec\n",
      ">>>> TOTAL TIME 9.20 sec\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "time spent: running network 0.41s; flow+mask computation 1.96\n",
      "estimated masks for 1 image(s) in 2.41 sec\n",
      ">>>> TOTAL TIME 2.41 sec\n",
      "exemple_data/max_projections/DMSO_4_MAX.tif\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "time spent: running network 0.28s; flow+mask computation 7.64\n",
      "estimated masks for 1 image(s) in 7.96 sec\n",
      ">>>> TOTAL TIME 7.96 sec\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "time spent: running network 0.26s; flow+mask computation 2.17\n",
      "estimated masks for 1 image(s) in 2.46 sec\n",
      ">>>> TOTAL TIME 2.46 sec\n",
      "exemple_data/max_projections/DMSO_5_MAX.tif\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "time spent: running network 0.26s; flow+mask computation 18.14\n",
      "estimated masks for 1 image(s) in 18.44 sec\n",
      ">>>> TOTAL TIME 18.44 sec\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "time spent: running network 0.27s; flow+mask computation 2.38\n",
      "estimated masks for 1 image(s) in 2.68 sec\n",
      ">>>> TOTAL TIME 2.68 sec\n",
      "exemple_data/max_projections/DMSO_6_MAX.tif\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "time spent: running network 0.25s; flow+mask computation 6.03\n",
      "estimated masks for 1 image(s) in 6.33 sec\n",
      ">>>> TOTAL TIME 6.33 sec\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "time spent: running network 0.27s; flow+mask computation 2.23\n",
      "estimated masks for 1 image(s) in 2.53 sec\n",
      ">>>> TOTAL TIME 2.53 sec\n",
      "exemple_data/max_projections/nutlin_1_MAX.tif\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "time spent: running network 0.27s; flow+mask computation 18.85\n",
      "estimated masks for 1 image(s) in 19.16 sec\n",
      ">>>> TOTAL TIME 19.16 sec\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "time spent: running network 0.26s; flow+mask computation 2.33\n",
      "estimated masks for 1 image(s) in 2.61 sec\n",
      ">>>> TOTAL TIME 2.61 sec\n",
      "exemple_data/max_projections/nutlin_2_MAX.tif\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "time spent: running network 0.25s; flow+mask computation 16.64\n",
      "estimated masks for 1 image(s) in 16.93 sec\n",
      ">>>> TOTAL TIME 16.93 sec\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "time spent: running network 0.27s; flow+mask computation 2.39\n",
      "estimated masks for 1 image(s) in 2.69 sec\n",
      ">>>> TOTAL TIME 2.69 sec\n",
      "exemple_data/max_projections/nutlin_3_MAX.tif\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "time spent: running network 0.25s; flow+mask computation 15.51\n",
      "estimated masks for 1 image(s) in 15.80 sec\n",
      ">>>> TOTAL TIME 15.80 sec\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "time spent: running network 0.34s; flow+mask computation 2.46\n",
      "estimated masks for 1 image(s) in 2.84 sec\n",
      ">>>> TOTAL TIME 2.84 sec\n",
      "exemple_data/max_projections/nutlin_4_MAX.tif\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "time spent: running network 0.31s; flow+mask computation 20.53\n",
      "estimated masks for 1 image(s) in 20.88 sec\n",
      ">>>> TOTAL TIME 20.88 sec\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "time spent: running network 0.27s; flow+mask computation 2.27\n",
      "estimated masks for 1 image(s) in 2.57 sec\n",
      ">>>> TOTAL TIME 2.57 sec\n",
      "exemple_data/max_projections/nutlin_5_MAX.tif\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "time spent: running network 0.26s; flow+mask computation 12.21\n",
      "estimated masks for 1 image(s) in 12.52 sec\n",
      ">>>> TOTAL TIME 12.52 sec\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "time spent: running network 0.27s; flow+mask computation 1.86\n",
      "estimated masks for 1 image(s) in 2.16 sec\n",
      ">>>> TOTAL TIME 2.16 sec\n",
      "exemple_data/max_projections/nutlin_6_MAX.tif\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "time spent: running network 0.26s; flow+mask computation 7.95\n",
      "estimated masks for 1 image(s) in 8.25 sec\n",
      ">>>> TOTAL TIME 8.25 sec\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "time spent: running network 0.26s; flow+mask computation 1.45\n",
      "estimated masks for 1 image(s) in 1.74 sec\n",
      ">>>> TOTAL TIME 1.74 sec\n"
     ]
    }
   ],
   "source": [
    "seg.cellpose_outlines(root_folder, \n",
    "                  cell_diameter=230, \n",
    "                  nucleus_diameter=100, \n",
    "                  save_masks=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sanity check will ensure all the nucleus are associated with the cell they are inside of. There are a couple of exclusion parameters in addition: cells that are more than 20 times smaller than the rest in the image will get excluded, and cell whose outline is more than 10% on the border of the image.\n",
    "\n",
    "DANGER: For now, this overwrites the outline files rather crudely. I'd advise making a copy of them, because if anything cause wrong, the original file might be gone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nutlin_1_MAX_cytosol_cp_outlines.txt\n",
      "nutlin_5_MAX_cytosol_cp_outlines.txt\n",
      "Cell 4 has no nucleus inside and was excluded.\n",
      "nutlin_4_MAX_cytosol_cp_outlines.txt\n",
      "Cell 5 is +20x smaller than the rest and was excluded\n",
      "Cell 6 is +20x smaller than the rest and was excluded\n",
      "Cell 7 is +20x smaller than the rest and was excluded\n",
      "Cell 8 is +20x smaller than the rest and was excluded\n",
      "Cell 11 is +20x smaller than the rest and was excluded\n",
      "Cell 12 is +20x smaller than the rest and was excluded\n",
      "Cell 1 is +10% on border and was excluded.\n",
      "Cell 10 is +10% on border and was excluded.\n",
      "DMSO_2_MAX_cytosol_cp_outlines.txt\n",
      "Cell 2 is +20x smaller than the rest and was excluded\n",
      "Cell 1 has no nucleus inside and was excluded.\n",
      "DMSO_6_MAX_cytosol_cp_outlines.txt\n",
      "Cell 5 has no nucleus inside and was excluded.\n",
      "Cell 6 has no nucleus inside and was excluded.\n",
      "nutlin_2_MAX_cytosol_cp_outlines.txt\n",
      "Cell 1 is +10% on border and was excluded.\n",
      "DMSO_4_MAX_cytosol_cp_outlines.txt\n",
      "Cell 1 is +10% on border and was excluded.\n",
      "nutlin_6_MAX_cytosol_cp_outlines.txt\n",
      "DMSO_1_MAX_cytosol_cp_outlines.txt\n",
      "DMSO_5_MAX_cytosol_cp_outlines.txt\n",
      "Cell 3 is +20x smaller than the rest and was excluded\n",
      "Cell 4 is +20x smaller than the rest and was excluded\n",
      "Cell 5 is +20x smaller than the rest and was excluded\n",
      "Cell 6 is +20x smaller than the rest and was excluded\n",
      "nutlin_3_MAX_cytosol_cp_outlines.txt\n",
      "Cell 2 is +20x smaller than the rest and was excluded\n",
      "Cell 4 is +10% on border and was excluded.\n",
      "DMSO_3_MAX_cytosol_cp_outlines.txt\n",
      "Cell 3 has no nucleus inside and was excluded.\n",
      "Cell 5 has no nucleus inside and was excluded.\n"
     ]
    }
   ],
   "source": [
    "sanitize.batch_sanity_check(root_folder,\n",
    "                    exclude_border=True,\n",
    "                    exclude_too_small=True,\n",
    "                    reassign_nucleus=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outline files can be loaded in ImageJ using the \"imagej_roi_converter.py\" macro provided in this folder.\n",
    "\n",
    "\n",
    "At this point we can generate the outline files compatible with FISHQuant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg.FQ_outlines_from_cp(root_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python376jvsc74a57bd06bb592209296cd01c15104ad459fec7efda459241065ece1923d14d5c00ced46"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
